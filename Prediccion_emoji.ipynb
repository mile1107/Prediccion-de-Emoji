{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICCI√ìN DE EMOJI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Librer√≠as a usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import emoji\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga y lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos de entrenamiento y de datos de los archivos csv\n",
    "names_cols_train = [\"Text\", \"Label\", \"C3\", \"C4\"]\n",
    "names_cols_test = [\"Text\", \"Label\"]\n",
    "train = pd.read_csv(\"DATOS_PROYECTO_4/train_emoji.csv\", header=None, names = names_cols_train)\n",
    "test = pd.read_csv(\"DATOS_PROYECTO_4/test_emoji.csv\", header=None, names = names_cols_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>never talk to me again</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am proud of your achievements</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is the worst day in my life</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miss you so much</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food is life</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Text  Label  C3    C4\n",
       "0           never talk to me again      3 NaN   NaN\n",
       "1  I am proud of your achievements      2 NaN   NaN\n",
       "2   It is the worst day in my life      3 NaN   NaN\n",
       "3                 Miss you so much      0 NaN   [0]\n",
       "4                     food is life      4 NaN   NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrar los 5 primeros datos de entrenamiento\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I want to eat\\t</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>he did not answer\\t</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>he got a raise\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>she got me a present\\t</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ha ha ha it was so funny\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Text  Label\n",
       "0             I want to eat\\t      4\n",
       "1         he did not answer\\t      3\n",
       "2            he got a raise\\t      2\n",
       "3      she got me a present\\t      0\n",
       "4  ha ha ha it was so funny\\t      2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrar los 5 primeros datos de entrenamiento\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. De etiquetas a Emojis\n",
    "<p>El texto est√° etiquetado con n√∫meros enteros que van del 0 al 4. Cada n√∫mero entero corresponde a un emoji espec√≠fico.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0  : ‚ù§Ô∏è\n",
      "Label 1  : ‚öæ\n",
      "Label 2  : üòÑ\n",
      "Label 3  : üòû\n",
      "Label 4  : üç¥\n"
     ]
    }
   ],
   "source": [
    "emoji_dictionary = {\"0\": \":heart:\", #-- :coraz√≥n: imprime un coraz√≥n negro en lugar de rojo dependiendo de la fuente\n",
    "                    \"1\": \":baseball:\",\n",
    "                    \"2\": \":smile:\",\n",
    "                    \"3\": \":disappointed:\",\n",
    "                    \"4\": \":fork_and_knife:\"}\n",
    "\n",
    "# Funci√≥n para convertir un n√∫meros entero en emoji imprimible\n",
    "def label_to_emoji(label):\n",
    "    return emoji.emojize(emoji_dictionary[str(label)], use_aliases=True)\n",
    "\n",
    "# Mostrar las etiquetas y sus respectivos emojis\n",
    "for i in range(5):\n",
    "    print(\"Label\", i, \" :\", label_to_emoji(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "never talk to me again  : üòû\n",
      "I am proud of your achievements  : üòÑ\n",
      "It is the worst day in my life  : üòû\n",
      "Miss you so much  : ‚ù§Ô∏è\n",
      "food is life  : üç¥\n"
     ]
    }
   ],
   "source": [
    "# Mostrar los 5 primeros textos y sus respectivos emojis\n",
    "data = train.values\n",
    "for i in range(5):\n",
    "    print(data[i][0], \" :\", label_to_emoji(data[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creamos el training y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[\"Text\"]\n",
    "X_test = test[\"Text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum words in sentence are: 10\n"
     ]
    }
   ],
   "source": [
    "maxLen = len(max(X_train, key=len).split())\n",
    "print('Maximum words in sentence are:',maxLen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Y's to one-hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = pd.get_dummies(train[\"Label\"])\n",
    "Y_test = pd.get_dummies(test[\"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±o de los datos de entrenamiento: (132,) (132, 5)\n",
      "Tama√±o de los datos de test: (56,) (56, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Tama√±o de los datos de entrenamiento:\", X_train.shape, Y_train.shape)\n",
    "print (\"Tama√±o de los datos de test:\", X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cargar los vectores Glove "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos representaciones de vectores de palabras en las palabras en la oraci√≥n, por lo que necesitamos representaciones de vectores de palabras de las palabras en las oraciones. Usaremos los vectores Glove para esta representaci√≥n. Basado en algunas iteraciones, los vectores 100 d parecen funcionar mejor para este caso.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file,encoding='utf-8') as f:\n",
    "        words = set()         # ensures unique values\n",
    "        word_to_vec_map = {}  # creamos un diciconario para mapear las palabras\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype='float32')\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}   # dictionario donde  mapeamos las palbras con el el indice\n",
    "        index_to_words = {}   # dictionario donde mapeamos el indice con la palabra\n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i = i + 1\n",
    "    return words_to_index, index_to_words, word_to_vec_map\n",
    "\n",
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('gloveEmbeddings/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos Keras para la implementaci√≥n del LSTM. Por lo tanto, necesitamos crear una 'capa de incrustaci√≥n'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    vocab_len = len(word_to_index) + 1                \n",
    "    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]      # dimension de los vectores Glove\n",
    "    \n",
    "    emb_matrix = np.zeros((vocab_len, emb_dim))      # Inicializar la matriz con ceros\n",
    "\n",
    "    # Establecer un subindice para cada fila\n",
    "    for word, index in word_to_index.items():\n",
    "        emb_matrix[index, :] = word_to_vec_map[word]\n",
    "\n",
    "    # Creamos \n",
    "    embedding_layer = Embedding(vocab_len, emb_dim, trainable=False)\n",
    "    embedding_layer.build((None,))\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiamos las sentencias a indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    m = X.shape[0]                               \n",
    "    X_indices = np.zeros((m, max_len))           # Initializamos la matriz con ceros\n",
    "    for i in range(m):\n",
    "        sentence_words = (X[i].lower()).split()  # partimos la sentencia en palabras\n",
    "        j = 0\n",
    "        for w in sentence_words:\n",
    "            X_indices[i, j] = word_to_index[w]   # vemos el indice de la palabra en la frase y le asifnamos vocavulario\n",
    "            j = j + 1\n",
    "            \n",
    "    return X_indices\n",
    "\n",
    "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
    "X_test_indices = sentences_to_indices(X_test, word_to_index, maxLen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Keras emojify LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_indices = Input((maxLen,), dtype = 'int32')\n",
    "embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "embeddings = embedding_layer(sentence_indices)   \n",
    "X = LSTM(128, return_sequences=True)(embeddings)\n",
    "X = Dropout(0.5)(X)\n",
    "X = LSTM(128, return_sequences=False)(X)\n",
    "X = Dropout(0.5)(X)\n",
    "X = Dense(5)(X)\n",
    "X = Activation('softmax')(X)\n",
    "    \n",
    "model = Model(sentence_indices, X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 10, 50)            20000050  \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 10, 128)           91648     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 10, 128)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 645       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,223,927\n",
      "Trainable params: 223,877\n",
      "Non-trainable params: 20,000,050\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 1.3788e-04 - accuracy: 1.0000 - val_loss: 3.0224 - val_accuracy: 0.6071\n",
      "Epoch 2/150\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.9246e-04 - accuracy: 1.0000 - val_loss: 3.0243 - val_accuracy: 0.5893\n",
      "Epoch 3/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.6987e-04 - accuracy: 1.0000 - val_loss: 3.0269 - val_accuracy: 0.5893\n",
      "Epoch 4/150\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.3751e-04 - accuracy: 1.0000 - val_loss: 3.0308 - val_accuracy: 0.6071\n",
      "Epoch 5/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.3596e-04 - accuracy: 1.0000 - val_loss: 3.0330 - val_accuracy: 0.6071\n",
      "Epoch 6/150\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 8.1739e-05 - accuracy: 1.0000 - val_loss: 3.0350 - val_accuracy: 0.6071\n",
      "Epoch 7/150\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.2543e-04 - accuracy: 1.0000 - val_loss: 3.0370 - val_accuracy: 0.6071\n",
      "Epoch 8/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.1866e-04 - accuracy: 1.0000 - val_loss: 3.0397 - val_accuracy: 0.6071\n",
      "Epoch 9/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.8029e-04 - accuracy: 1.0000 - val_loss: 3.0434 - val_accuracy: 0.6071\n",
      "Epoch 10/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.6170e-04 - accuracy: 1.0000 - val_loss: 3.0479 - val_accuracy: 0.6071\n",
      "Epoch 11/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.1842e-04 - accuracy: 1.0000 - val_loss: 3.0510 - val_accuracy: 0.6071\n",
      "Epoch 12/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.2805e-04 - accuracy: 1.0000 - val_loss: 3.0538 - val_accuracy: 0.6071\n",
      "Epoch 13/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 9.6942e-05 - accuracy: 1.0000 - val_loss: 3.0555 - val_accuracy: 0.6071\n",
      "Epoch 14/150\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.1862e-04 - accuracy: 1.0000 - val_loss: 3.0584 - val_accuracy: 0.6071\n",
      "Epoch 15/150\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.4264e-04 - accuracy: 1.0000 - val_loss: 3.0546 - val_accuracy: 0.6071\n",
      "Epoch 16/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.8611e-04 - accuracy: 1.0000 - val_loss: 3.0575 - val_accuracy: 0.6071\n",
      "Epoch 17/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 2.1893e-04 - accuracy: 1.0000 - val_loss: 3.0624 - val_accuracy: 0.6071\n",
      "Epoch 18/150\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.0935e-04 - accuracy: 1.0000 - val_loss: 3.0671 - val_accuracy: 0.5893\n",
      "Epoch 19/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.5168e-04 - accuracy: 1.0000 - val_loss: 3.0697 - val_accuracy: 0.5893\n",
      "Epoch 20/150\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.1152e-04 - accuracy: 1.0000 - val_loss: 3.0729 - val_accuracy: 0.5893\n",
      "Epoch 21/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 2.2422e-04 - accuracy: 1.0000 - val_loss: 3.0764 - val_accuracy: 0.5893\n",
      "Epoch 22/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.3330e-04 - accuracy: 1.0000 - val_loss: 3.0806 - val_accuracy: 0.5893\n",
      "Epoch 23/150\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 8.0850e-05 - accuracy: 1.0000 - val_loss: 3.0840 - val_accuracy: 0.6071\n",
      "Epoch 24/150\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.4572e-04 - accuracy: 1.0000 - val_loss: 3.0872 - val_accuracy: 0.6071\n",
      "Epoch 25/150\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 1.5011e-04 - accuracy: 1.0000 - val_loss: 3.0910 - val_accuracy: 0.6071\n",
      "Epoch 26/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.3901e-04 - accuracy: 1.0000 - val_loss: 3.0954 - val_accuracy: 0.5893\n",
      "Epoch 27/150\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.0505e-04 - accuracy: 1.0000 - val_loss: 3.1001 - val_accuracy: 0.5893\n",
      "Epoch 28/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.3302e-04 - accuracy: 1.0000 - val_loss: 3.1015 - val_accuracy: 0.5893\n",
      "Epoch 29/150\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.4239e-04 - accuracy: 1.0000 - val_loss: 3.1019 - val_accuracy: 0.5893\n",
      "Epoch 30/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.1374e-04 - accuracy: 1.0000 - val_loss: 3.1023 - val_accuracy: 0.5893\n",
      "Epoch 31/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.7182e-04 - accuracy: 1.0000 - val_loss: 3.1055 - val_accuracy: 0.5893\n",
      "Epoch 32/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.1439e-04 - accuracy: 1.0000 - val_loss: 3.1086 - val_accuracy: 0.5893\n",
      "Epoch 33/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.5556e-04 - accuracy: 1.0000 - val_loss: 3.1134 - val_accuracy: 0.5893\n",
      "Epoch 34/150\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 8.5542e-05 - accuracy: 1.0000 - val_loss: 3.1177 - val_accuracy: 0.5893\n",
      "Epoch 35/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 8.5658e-05 - accuracy: 1.0000 - val_loss: 3.1208 - val_accuracy: 0.5893\n",
      "Epoch 36/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.6355e-04 - accuracy: 1.0000 - val_loss: 3.1278 - val_accuracy: 0.5893\n",
      "Epoch 37/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 8.4171e-05 - accuracy: 1.0000 - val_loss: 3.1322 - val_accuracy: 0.5893\n",
      "Epoch 38/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.2079e-04 - accuracy: 1.0000 - val_loss: 3.1357 - val_accuracy: 0.5893\n",
      "Epoch 39/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 7.0826e-05 - accuracy: 1.0000 - val_loss: 3.1389 - val_accuracy: 0.5893\n",
      "Epoch 40/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 7.5348e-05 - accuracy: 1.0000 - val_loss: 3.1423 - val_accuracy: 0.5893\n",
      "Epoch 41/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 8.9022e-05 - accuracy: 1.0000 - val_loss: 3.1448 - val_accuracy: 0.5893\n",
      "Epoch 42/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.0644e-04 - accuracy: 1.0000 - val_loss: 3.1487 - val_accuracy: 0.5893\n",
      "Epoch 43/150\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 1.1205e-04 - accuracy: 1.0000 - val_loss: 3.1537 - val_accuracy: 0.5893\n",
      "Epoch 44/150\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 9.9458e-05 - accuracy: 1.0000 - val_loss: 3.1580 - val_accuracy: 0.5893\n",
      "Epoch 45/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.2605e-04 - accuracy: 1.0000 - val_loss: 3.1606 - val_accuracy: 0.5893\n",
      "Epoch 46/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 8.1465e-05 - accuracy: 1.0000 - val_loss: 3.1629 - val_accuracy: 0.5893\n",
      "Epoch 47/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.1964e-04 - accuracy: 1.0000 - val_loss: 3.1663 - val_accuracy: 0.5893\n",
      "Epoch 48/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.0141e-04 - accuracy: 1.0000 - val_loss: 3.1693 - val_accuracy: 0.5893\n",
      "Epoch 49/150\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 8.5441e-05 - accuracy: 1.0000 - val_loss: 3.1713 - val_accuracy: 0.5893\n",
      "Epoch 50/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.1426e-04 - accuracy: 1.0000 - val_loss: 3.1727 - val_accuracy: 0.5893\n",
      "Epoch 51/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 7.5945e-05 - accuracy: 1.0000 - val_loss: 3.1754 - val_accuracy: 0.5893\n",
      "Epoch 52/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 9.4266e-05 - accuracy: 1.0000 - val_loss: 3.1791 - val_accuracy: 0.5893\n",
      "Epoch 53/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.2135e-04 - accuracy: 1.0000 - val_loss: 3.1825 - val_accuracy: 0.5893\n",
      "Epoch 54/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.1571e-04 - accuracy: 1.0000 - val_loss: 3.1842 - val_accuracy: 0.5893\n",
      "Epoch 55/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.0341e-04 - accuracy: 1.0000 - val_loss: 3.1846 - val_accuracy: 0.5893\n",
      "Epoch 56/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 7.9518e-05 - accuracy: 1.0000 - val_loss: 3.1862 - val_accuracy: 0.5893\n",
      "Epoch 57/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 8.7263e-05 - accuracy: 1.0000 - val_loss: 3.1875 - val_accuracy: 0.5893\n",
      "Epoch 58/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 9.3180e-05 - accuracy: 1.0000 - val_loss: 3.1886 - val_accuracy: 0.5893\n",
      "Epoch 59/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 9.2876e-05 - accuracy: 1.0000 - val_loss: 3.1912 - val_accuracy: 0.5893\n",
      "Epoch 60/150\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 7.9179e-05 - accuracy: 1.0000 - val_loss: 3.1937 - val_accuracy: 0.5893\n",
      "Epoch 61/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.0461e-04 - accuracy: 1.0000 - val_loss: 3.1969 - val_accuracy: 0.5893\n",
      "Epoch 62/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.0903e-04 - accuracy: 1.0000 - val_loss: 3.1967 - val_accuracy: 0.5893\n",
      "Epoch 63/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 8.0254e-05 - accuracy: 1.0000 - val_loss: 3.1957 - val_accuracy: 0.5893\n",
      "Epoch 64/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 9.7742e-05 - accuracy: 1.0000 - val_loss: 3.1971 - val_accuracy: 0.5893\n",
      "Epoch 65/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.1947e-04 - accuracy: 1.0000 - val_loss: 3.1986 - val_accuracy: 0.5893\n",
      "Epoch 66/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.1190e-04 - accuracy: 1.0000 - val_loss: 3.1985 - val_accuracy: 0.5893\n",
      "Epoch 67/150\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.1705e-04 - accuracy: 1.0000 - val_loss: 3.2009 - val_accuracy: 0.5893\n",
      "Epoch 68/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 9.3869e-05 - accuracy: 1.0000 - val_loss: 3.2045 - val_accuracy: 0.5893\n",
      "Epoch 69/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 6.5399e-05 - accuracy: 1.0000 - val_loss: 3.2076 - val_accuracy: 0.5893\n",
      "Epoch 70/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 6.4082e-05 - accuracy: 1.0000 - val_loss: 3.2106 - val_accuracy: 0.5893\n",
      "Epoch 71/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 9.6949e-05 - accuracy: 1.0000 - val_loss: 3.2139 - val_accuracy: 0.5893\n",
      "Epoch 72/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 7.1153e-05 - accuracy: 1.0000 - val_loss: 3.2162 - val_accuracy: 0.5893\n",
      "Epoch 73/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 8.6551e-05 - accuracy: 1.0000 - val_loss: 3.2195 - val_accuracy: 0.5893\n",
      "Epoch 74/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.1770e-04 - accuracy: 1.0000 - val_loss: 3.2226 - val_accuracy: 0.5893\n",
      "Epoch 75/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 9.9660e-05 - accuracy: 1.0000 - val_loss: 3.2256 - val_accuracy: 0.5893\n",
      "Epoch 76/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 6.4077e-05 - accuracy: 1.0000 - val_loss: 3.2290 - val_accuracy: 0.5893\n",
      "Epoch 77/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 7.8251e-05 - accuracy: 1.0000 - val_loss: 3.2320 - val_accuracy: 0.5893\n",
      "Epoch 78/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.4041e-04 - accuracy: 1.0000 - val_loss: 3.2347 - val_accuracy: 0.5893\n",
      "Epoch 79/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 9.2317e-05 - accuracy: 1.0000 - val_loss: 3.2342 - val_accuracy: 0.5893\n",
      "Epoch 80/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 9.4361e-05 - accuracy: 1.0000 - val_loss: 3.2352 - val_accuracy: 0.5893\n",
      "Epoch 81/150\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 8.8613e-05 - accuracy: 1.0000 - val_loss: 3.2375 - val_accuracy: 0.5893\n",
      "Epoch 82/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 8.5752e-05 - accuracy: 1.0000 - val_loss: 3.2397 - val_accuracy: 0.5893\n",
      "Epoch 83/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.3105e-04 - accuracy: 1.0000 - val_loss: 3.2428 - val_accuracy: 0.5893\n",
      "Epoch 84/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 8.3357e-05 - accuracy: 1.0000 - val_loss: 3.2469 - val_accuracy: 0.5893\n",
      "Epoch 85/150\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 6.9843e-05 - accuracy: 1.0000 - val_loss: 3.2501 - val_accuracy: 0.5893\n",
      "Epoch 86/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.0369e-04 - accuracy: 1.0000 - val_loss: 3.2551 - val_accuracy: 0.5893\n",
      "Epoch 87/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 8.3445e-05 - accuracy: 1.0000 - val_loss: 3.2583 - val_accuracy: 0.5893\n",
      "Epoch 88/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 8.1686e-05 - accuracy: 1.0000 - val_loss: 3.2621 - val_accuracy: 0.5893\n",
      "Epoch 89/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 9.3580e-05 - accuracy: 1.0000 - val_loss: 3.2676 - val_accuracy: 0.5893\n",
      "Epoch 90/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.5220e-04 - accuracy: 1.0000 - val_loss: 3.2729 - val_accuracy: 0.5893\n",
      "Epoch 91/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 7.8038e-05 - accuracy: 1.0000 - val_loss: 3.2796 - val_accuracy: 0.6071\n",
      "Epoch 92/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 9.1579e-05 - accuracy: 1.0000 - val_loss: 3.2857 - val_accuracy: 0.6071\n",
      "Epoch 93/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.0074e-04 - accuracy: 1.0000 - val_loss: 3.2926 - val_accuracy: 0.5893\n",
      "Epoch 94/150\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.3875e-04 - accuracy: 1.0000 - val_loss: 3.2974 - val_accuracy: 0.5893\n",
      "Epoch 95/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 7.1117e-05 - accuracy: 1.0000 - val_loss: 3.3037 - val_accuracy: 0.5893\n",
      "Epoch 96/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 6.4012e-05 - accuracy: 1.0000 - val_loss: 3.3079 - val_accuracy: 0.5893\n",
      "Epoch 97/150\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 7.7737e-05 - accuracy: 1.0000 - val_loss: 3.3095 - val_accuracy: 0.5893\n",
      "Epoch 98/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 4.5621e-05 - accuracy: 1.0000 - val_loss: 3.3104 - val_accuracy: 0.5893\n",
      "Epoch 99/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 9.8462e-05 - accuracy: 1.0000 - val_loss: 3.3113 - val_accuracy: 0.5893\n",
      "Epoch 100/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 9.6866e-05 - accuracy: 1.0000 - val_loss: 3.3139 - val_accuracy: 0.5893\n",
      "Epoch 101/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 4.8903e-05 - accuracy: 1.0000 - val_loss: 3.3172 - val_accuracy: 0.5893\n",
      "Epoch 102/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 6.9755e-05 - accuracy: 1.0000 - val_loss: 3.3202 - val_accuracy: 0.5893\n",
      "Epoch 103/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 5.9481e-05 - accuracy: 1.0000 - val_loss: 3.3222 - val_accuracy: 0.5893\n",
      "Epoch 104/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.0871e-04 - accuracy: 1.0000 - val_loss: 3.3254 - val_accuracy: 0.5893\n",
      "Epoch 105/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 4.4764e-05 - accuracy: 1.0000 - val_loss: 3.3275 - val_accuracy: 0.5893\n",
      "Epoch 106/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 7.2137e-05 - accuracy: 1.0000 - val_loss: 3.3288 - val_accuracy: 0.5893\n",
      "Epoch 107/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 7.4413e-05 - accuracy: 1.0000 - val_loss: 3.3331 - val_accuracy: 0.5893\n",
      "Epoch 108/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 5.6511e-05 - accuracy: 1.0000 - val_loss: 3.3405 - val_accuracy: 0.5893\n",
      "Epoch 109/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 8.4256e-05 - accuracy: 1.0000 - val_loss: 3.3406 - val_accuracy: 0.5893\n",
      "Epoch 110/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 5.9835e-05 - accuracy: 1.0000 - val_loss: 3.3407 - val_accuracy: 0.5893\n",
      "Epoch 111/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 6.2304e-05 - accuracy: 1.0000 - val_loss: 3.3415 - val_accuracy: 0.5893\n",
      "Epoch 112/150\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 5.8077e-05 - accuracy: 1.0000 - val_loss: 3.3426 - val_accuracy: 0.5893\n",
      "Epoch 113/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.1280e-04 - accuracy: 1.0000 - val_loss: 3.3461 - val_accuracy: 0.5893\n",
      "Epoch 114/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 8.5676e-05 - accuracy: 1.0000 - val_loss: 3.3486 - val_accuracy: 0.5893\n",
      "Epoch 115/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 6.7968e-05 - accuracy: 1.0000 - val_loss: 3.3454 - val_accuracy: 0.5893\n",
      "Epoch 116/150\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 8.6511e-05 - accuracy: 1.0000 - val_loss: 3.3451 - val_accuracy: 0.5893\n",
      "Epoch 117/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 6.5283e-05 - accuracy: 1.0000 - val_loss: 3.3471 - val_accuracy: 0.5893\n",
      "Epoch 118/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 9.3923e-05 - accuracy: 1.0000 - val_loss: 3.3503 - val_accuracy: 0.5893\n",
      "Epoch 119/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.2088e-04 - accuracy: 1.0000 - val_loss: 3.3543 - val_accuracy: 0.5893\n",
      "Epoch 120/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.0363e-04 - accuracy: 1.0000 - val_loss: 3.3560 - val_accuracy: 0.5893\n",
      "Epoch 121/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 4.7127e-05 - accuracy: 1.0000 - val_loss: 3.3584 - val_accuracy: 0.5893\n",
      "Epoch 122/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 5.2264e-05 - accuracy: 1.0000 - val_loss: 3.3609 - val_accuracy: 0.5893\n",
      "Epoch 123/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 6.2527e-05 - accuracy: 1.0000 - val_loss: 3.3637 - val_accuracy: 0.5893\n",
      "Epoch 124/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 9.0652e-05 - accuracy: 1.0000 - val_loss: 3.3668 - val_accuracy: 0.5893\n",
      "Epoch 125/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 7.9001e-05 - accuracy: 1.0000 - val_loss: 3.3684 - val_accuracy: 0.5893\n",
      "Epoch 126/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 6.6572e-05 - accuracy: 1.0000 - val_loss: 3.3698 - val_accuracy: 0.5893\n",
      "Epoch 127/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 7.9080e-05 - accuracy: 1.0000 - val_loss: 3.3786 - val_accuracy: 0.5893\n",
      "Epoch 128/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 6.1096e-05 - accuracy: 1.0000 - val_loss: 3.3842 - val_accuracy: 0.5893\n",
      "Epoch 129/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 5.2563e-05 - accuracy: 1.0000 - val_loss: 3.3884 - val_accuracy: 0.5893\n",
      "Epoch 130/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 5.0815e-05 - accuracy: 1.0000 - val_loss: 3.3926 - val_accuracy: 0.5893\n",
      "Epoch 131/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 6.7625e-05 - accuracy: 1.0000 - val_loss: 3.3949 - val_accuracy: 0.5893\n",
      "Epoch 132/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.3105e-04 - accuracy: 1.0000 - val_loss: 3.3983 - val_accuracy: 0.5893\n",
      "Epoch 133/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 6.2004e-05 - accuracy: 1.0000 - val_loss: 3.4034 - val_accuracy: 0.5893\n",
      "Epoch 134/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 6.0808e-05 - accuracy: 1.0000 - val_loss: 3.4078 - val_accuracy: 0.5893\n",
      "Epoch 135/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.0523e-04 - accuracy: 1.0000 - val_loss: 3.4114 - val_accuracy: 0.5893\n",
      "Epoch 136/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 4.9388e-05 - accuracy: 1.0000 - val_loss: 3.4146 - val_accuracy: 0.5893\n",
      "Epoch 137/150\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 8.4605e-05 - accuracy: 1.0000 - val_loss: 3.4192 - val_accuracy: 0.5893\n",
      "Epoch 138/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 6.9496e-05 - accuracy: 1.0000 - val_loss: 3.4257 - val_accuracy: 0.5893\n",
      "Epoch 139/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 7.4655e-05 - accuracy: 1.0000 - val_loss: 3.4326 - val_accuracy: 0.5893\n",
      "Epoch 140/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 4.6005e-05 - accuracy: 1.0000 - val_loss: 3.4368 - val_accuracy: 0.5893\n",
      "Epoch 141/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 4.6243e-05 - accuracy: 1.0000 - val_loss: 3.4396 - val_accuracy: 0.5893\n",
      "Epoch 142/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 4.8516e-05 - accuracy: 1.0000 - val_loss: 3.4426 - val_accuracy: 0.5893\n",
      "Epoch 143/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 4.7485e-05 - accuracy: 1.0000 - val_loss: 3.4453 - val_accuracy: 0.5893\n",
      "Epoch 144/150\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 5.4351e-05 - accuracy: 1.0000 - val_loss: 3.4481 - val_accuracy: 0.5893\n",
      "Epoch 145/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 4.1620e-05 - accuracy: 1.0000 - val_loss: 3.4500 - val_accuracy: 0.5893\n",
      "Epoch 146/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 4.5489e-05 - accuracy: 1.0000 - val_loss: 3.4525 - val_accuracy: 0.5893\n",
      "Epoch 147/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 5.8334e-05 - accuracy: 1.0000 - val_loss: 3.4556 - val_accuracy: 0.5893\n",
      "Epoch 148/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 6.5163e-05 - accuracy: 1.0000 - val_loss: 3.4575 - val_accuracy: 0.5893\n",
      "Epoch 149/150\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 3.8906e-05 - accuracy: 1.0000 - val_loss: 3.4602 - val_accuracy: 0.5893\n",
      "Epoch 150/150\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 2.5973e-05 - accuracy: 1.0000 - val_loss: 3.4627 - val_accuracy: 0.5893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e2b35ee370>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_indices, Y_train, epochs = 150, batch_size = 16, shuffle=True, validation_data=(X_test_indices, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step - loss: 3.0215 - accuracy: 0.6071\n",
      "\n",
      "Test accuracy =  0.6071428656578064\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test_indices, Y_test)\n",
    "print()\n",
    "print(\"Test accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_lbl = test[\"Label\"]\n",
    "Y_test_oh = pd.get_dummies(Y_test_lbl)\n",
    "X_test_indices = sentences_to_indices(test[\"Text\"], word_to_index, maxLen)\n",
    "pred = model.predict(X_test_indices)\n",
    "\n",
    "tabla_predict = []\n",
    "for i in range(len(X_test)):\n",
    "    x = X_test_indices\n",
    "    num = np.argmax(pred[i])\n",
    "    tabla_predict.append([X_test[i],label_to_emoji(Y_test_lbl[i]),label_to_emoji(num).strip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto                                  Label    Predicci√≥n\n",
      "-------------------------------------  -------  ------------\n",
      "I want to eat                          üç¥       üç¥\n",
      "he did not answer                      üòû       üòû\n",
      "he got a raise                         üòÑ       üòû\n",
      "she got me a present                   ‚ù§Ô∏è        üòÑ\n",
      "ha ha ha it was so funny               üòÑ       üòÑ\n",
      "he is a good friend                    ‚ù§Ô∏è        üòÑ\n",
      "I am upset                             ‚ù§Ô∏è        üòû\n",
      "We had such a lovely dinner tonight    ‚ù§Ô∏è        üòÑ\n",
      "where is the food                      üç¥       üç¥\n",
      "Stop making this joke ha ha ha         üòÑ       üòÑ\n",
      "where is the ball                      ‚öæ       ‚öæ\n",
      "work is hard                           üòû       üòÑ\n",
      "This girl is messing with me           üòû       ‚ù§Ô∏è\n",
      "are you serious ha ha                  üòÑ       üòû\n",
      "Let us go play baseball                ‚öæ       ‚öæ\n",
      "This stupid grader is not working      üòû       üòû\n",
      "work is horrible                       üòû       üòû\n",
      "Congratulation for having a baby       üòÑ       üòÑ\n",
      "stop messing around                    üòû       üòû\n",
      "any suggestions for dinner             üç¥       üòÑ\n",
      "I love taking breaks                   ‚ù§Ô∏è        ‚ù§Ô∏è\n",
      "you brighten my day                    üòÑ       ‚ù§Ô∏è\n",
      "I boiled rice                          üç¥       üç¥\n",
      "she is a bully                         üòû       ‚ù§Ô∏è\n",
      "Why are you feeling bad                üòû       üòû\n",
      "I am upset                             üòû       üòû\n",
      "I worked during my birthday            üòû       üòÑ\n",
      "My grandmother is the love of my life  ‚ù§Ô∏è        ‚ù§Ô∏è\n",
      "enjoy your break                       üòÑ       ‚öæ\n",
      "valentine day is near                  ‚ù§Ô∏è        üòÑ\n",
      "I miss you so much                     ‚ù§Ô∏è        ‚ù§Ô∏è\n",
      "throw the ball                         ‚öæ       ‚öæ\n",
      "My life is so boring                   üòû       üòû\n",
      "she said yes                           üòÑ       üòÑ\n",
      "will you be my valentine               ‚ù§Ô∏è        üòÑ\n",
      "he can pitch really well               ‚öæ       ‚öæ\n",
      "dance with me                          üòÑ       üòÑ\n",
      "I am starving                          üç¥       üç¥\n",
      "See you at the restaurant              üç¥       üç¥\n",
      "I like to laugh                        üòÑ       üòÑ\n",
      "I will go dance                        üòÑ       ‚öæ\n",
      "I like your jacket                     üòÑ       ‚ù§Ô∏è\n",
      "i miss her                             ‚ù§Ô∏è        ‚ù§Ô∏è\n",
      "what is your favorite baseball game    ‚öæ       ‚öæ\n",
      "Good job                               üòÑ       üòÑ\n",
      "I love to the stars and back           ‚ù§Ô∏è        üòÑ\n",
      "What you did was awesome               üòÑ       üòû\n",
      "ha ha ha lol                           üòÑ       üòÑ\n",
      "I want to joke                         üòÑ       üòû\n",
      "go away                                üòû       ‚öæ\n",
      "yesterday we lost again                üòû       üòû\n",
      "family is all I have                   ‚ù§Ô∏è        ‚ù§Ô∏è\n",
      "you are failing this exercise          üòû       üòû\n",
      "Good joke                              üòÑ       üòÑ\n",
      "You totally deserve this prize         üòÑ       üòû\n",
      "I did not have breakfast               üòû       üç¥\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(tabla_predict, headers=[\"Texto\", \"Label\", \"Predicci√≥n\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
