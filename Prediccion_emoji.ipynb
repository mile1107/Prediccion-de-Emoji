{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICCI√ìN DE EMOJI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Librer√≠as a usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import emoji\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga y lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos de entrenamiento y de datos de los archivos csv\n",
    "names_cols_train = [\"Text\", \"Label\", \"C3\", \"C4\"]\n",
    "names_cols_test = [\"Text\", \"Label\"]\n",
    "train = pd.read_csv(\"DATOS_PROYECTO_4/train_emoji.csv\", header=None, names = names_cols_train)\n",
    "test = pd.read_csv(\"DATOS_PROYECTO_4/test_emoji.csv\", header=None, names = names_cols_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>never talk to me again</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am proud of your achievements</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is the worst day in my life</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miss you so much</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food is life</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Text  Label  C3    C4\n",
       "0           never talk to me again      3 NaN   NaN\n",
       "1  I am proud of your achievements      2 NaN   NaN\n",
       "2   It is the worst day in my life      3 NaN   NaN\n",
       "3                 Miss you so much      0 NaN   [0]\n",
       "4                     food is life      4 NaN   NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrar los 5 primeros datos de entrenamiento\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I want to eat\\t</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>he did not answer\\t</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>he got a raise\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>she got me a present\\t</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ha ha ha it was so funny\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Text  Label\n",
       "0             I want to eat\\t      4\n",
       "1         he did not answer\\t      3\n",
       "2            he got a raise\\t      2\n",
       "3      she got me a present\\t      0\n",
       "4  ha ha ha it was so funny\\t      2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrar los 5 primeros datos de entrenamiento\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. De etiquetas a Emojis\n",
    "<p>El texto est√° etiquetado con n√∫meros enteros que van del 0 al 4. Cada n√∫mero entero corresponde a un emoji espec√≠fico.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0  : ‚ù§Ô∏è\n",
      "Label 1  : ‚öæ\n",
      "Label 2  : üòÑ\n",
      "Label 3  : üòû\n",
      "Label 4  : üç¥\n"
     ]
    }
   ],
   "source": [
    "emoji_dictionary = {\"0\": \":heart:\", #-- :coraz√≥n: imprime un coraz√≥n negro en lugar de rojo dependiendo de la fuente\n",
    "                    \"1\": \":baseball:\",\n",
    "                    \"2\": \":smile:\",\n",
    "                    \"3\": \":disappointed:\",\n",
    "                    \"4\": \":fork_and_knife:\"}\n",
    "\n",
    "# Funci√≥n para convertir un n√∫meros entero en emoji imprimible\n",
    "def label_to_emoji(label):\n",
    "    return emoji.emojize(emoji_dictionary[str(label)], use_aliases=True)\n",
    "\n",
    "# Mostrar las etiquetas y sus respectivos emojis\n",
    "for i in range(5):\n",
    "    print(\"Label\", i, \" :\", label_to_emoji(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "never talk to me again  : üòû\n",
      "I am proud of your achievements  : üòÑ\n",
      "It is the worst day in my life  : üòû\n",
      "Miss you so much  : ‚ù§Ô∏è\n",
      "food is life  : üç¥\n"
     ]
    }
   ],
   "source": [
    "# Mostrar los 5 primeros textos y sus respectivos emojis\n",
    "data = train.values\n",
    "for i in range(5):\n",
    "    print(data[i][0], \" :\", label_to_emoji(data[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[\"Text\"]\n",
    "X_test = test[\"Text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum words in sentence are: 10\n"
     ]
    }
   ],
   "source": [
    "maxLen = len(max(X_train, key=len).split())\n",
    "print('Maximum words in sentence are:',maxLen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Y's to one-hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = pd.get_dummies(train[\"Label\"])\n",
    "Y_test = pd.get_dummies(test[\"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±o de los datos de entrenamiento: (132,) (132, 5)\n",
      "Tama√±o de los datos de test: (56,) (56, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Tama√±o de los datos de entrenamiento:\", X_train.shape, Y_train.shape)\n",
    "print (\"Tama√±o de los datos de test:\", X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load GloVe Embedding Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using word vector representations of the words in the sentence so we need word vector representations of the words in the sentences. We will use the Glove vectors for this representation. Based on few iterations 100 d vectors seem to work best for this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file,encoding='utf-8') as f:\n",
    "        words = set()         # ensures unique values\n",
    "        word_to_vec_map = {}  # this will be a dictionary mapping words to their vectors\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype='float32')\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}   # dictionary mapping words to their index in the dictionary\n",
    "        index_to_words = {}   # dictionary mapping index to the word in the dictionary\n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i = i + 1\n",
    "    return words_to_index, index_to_words, word_to_vec_map\n",
    "\n",
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('Glove_Embeddings/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using Keras for implementation of the LSTM. We thus need to create an 'embedding layer'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    vocab_len = len(word_to_index) + 1               # +1 for Keras  \n",
    "    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]      # dimensionality of your GloVe word vectors\n",
    "    \n",
    "    emb_matrix = np.zeros((vocab_len, emb_dim))      # Initialization with zeros\n",
    "    \n",
    "    # Set each row \"index\" of the embedding matrix to be the word vector representation of the \"index\"th word of the vocabulary\n",
    "    for word, index in word_to_index.items():\n",
    "        emb_matrix[index, :] = word_to_vec_map[word]\n",
    "\n",
    "    # Define Keras embedding layer with the correct output/input sizes\n",
    "    embedding_layer = Embedding(vocab_len, emb_dim, trainable=False)\n",
    "    \n",
    "    # Build the embedding layer\n",
    "    embedding_layer.build((None,))\n",
    "    \n",
    "    # Set the weights of the embedding layer to the embedding matrix. Your layer is now pretrained.\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to convert all training sentences into lists of indices, and then zero-pad all these lists so that their length is the length of the longest sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    m = X.shape[0]                               # number of training examples\n",
    "    X_indices = np.zeros((m, max_len))           # Initialize with zeros\n",
    "    for i in range(m):\n",
    "        sentence_words = (X[i].lower()).split()  # split each sentence into words\n",
    "        j = 0\n",
    "        for w in sentence_words:\n",
    "            X_indices[i, j] = word_to_index[w]   # lookup index of word from vocabulary\n",
    "            j = j + 1\n",
    "            \n",
    "    return X_indices\n",
    "\n",
    "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
    "X_test_indices = sentences_to_indices(X_test, word_to_index, maxLen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Keras emojify LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_indices = Input((maxLen,), dtype = 'int32')\n",
    "embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "embeddings = embedding_layer(sentence_indices)   \n",
    "X = LSTM(128, return_sequences=True)(embeddings)\n",
    "X = Dropout(0.5)(X)\n",
    "X = LSTM(128, return_sequences=False)(X)\n",
    "X = Dropout(0.5)(X)\n",
    "X = Dense(5)(X)\n",
    "X = Activation('softmax')(X)\n",
    "    \n",
    "model = Model(sentence_indices, X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 10)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 10, 50)            20000050  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 10, 128)           91648     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 20,223,927\n",
      "Trainable params: 223,877\n",
      "Non-trainable params: 20,000,050\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "9/9 [==============================] - 3s 90ms/step - loss: 1.5677 - accuracy: 0.3712 - val_loss: 1.5258 - val_accuracy: 0.3036\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.4807 - accuracy: 0.3788 - val_loss: 1.4421 - val_accuracy: 0.3750\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.3376 - accuracy: 0.5379 - val_loss: 1.3550 - val_accuracy: 0.5357\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.1184 - accuracy: 0.6288 - val_loss: 1.2164 - val_accuracy: 0.5536\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.9180 - accuracy: 0.6818 - val_loss: 1.1677 - val_accuracy: 0.5357\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.7749 - accuracy: 0.7500 - val_loss: 1.2280 - val_accuracy: 0.5536\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6584 - accuracy: 0.7273 - val_loss: 1.1282 - val_accuracy: 0.5536\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6291 - accuracy: 0.8030 - val_loss: 0.9896 - val_accuracy: 0.6250\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4401 - accuracy: 0.8712 - val_loss: 0.9751 - val_accuracy: 0.5893\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4355 - accuracy: 0.8636 - val_loss: 1.0287 - val_accuracy: 0.5714\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.3743 - accuracy: 0.8561 - val_loss: 1.1173 - val_accuracy: 0.5357\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3328 - accuracy: 0.8939 - val_loss: 1.1819 - val_accuracy: 0.5714\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2335 - accuracy: 0.9091 - val_loss: 1.0914 - val_accuracy: 0.5714\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2172 - accuracy: 0.9318 - val_loss: 1.0777 - val_accuracy: 0.5714\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2052 - accuracy: 0.9242 - val_loss: 1.1295 - val_accuracy: 0.6607\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1470 - accuracy: 0.9621 - val_loss: 1.1773 - val_accuracy: 0.6071\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0991 - accuracy: 0.98 - 0s 16ms/step - loss: 0.1186 - accuracy: 0.9697 - val_loss: 1.3508 - val_accuracy: 0.6250\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3336 - accuracy: 0.9167 - val_loss: 1.3892 - val_accuracy: 0.5714\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2423 - accuracy: 0.9242 - val_loss: 1.2417 - val_accuracy: 0.6071\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1908 - accuracy: 0.9470 - val_loss: 1.1137 - val_accuracy: 0.6071\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1125 - accuracy: 0.9697 - val_loss: 1.4693 - val_accuracy: 0.6607\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0979 - accuracy: 0.9697 - val_loss: 1.4901 - val_accuracy: 0.6071\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0729 - accuracy: 0.9773 - val_loss: 1.6140 - val_accuracy: 0.6607\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1165 - accuracy: 0.9621 - val_loss: 1.4220 - val_accuracy: 0.6071\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0584 - accuracy: 0.9848 - val_loss: 1.3520 - val_accuracy: 0.5893\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0812 - accuracy: 0.9697 - val_loss: 1.8311 - val_accuracy: 0.6250\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1657 - accuracy: 0.9394 - val_loss: 1.4222 - val_accuracy: 0.6429\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1149 - accuracy: 0.9470 - val_loss: 1.1107 - val_accuracy: 0.6786\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0873 - accuracy: 0.9773 - val_loss: 1.1882 - val_accuracy: 0.6607\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0594 - accuracy: 0.9773 - val_loss: 1.2821 - val_accuracy: 0.6429\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0583 - accuracy: 0.9773 - val_loss: 1.5377 - val_accuracy: 0.5893\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1223 - accuracy: 0.9773 - val_loss: 1.5702 - val_accuracy: 0.6250\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1093 - accuracy: 0.9773 - val_loss: 1.6701 - val_accuracy: 0.6429\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1736 - accuracy: 0.9470 - val_loss: 1.6194 - val_accuracy: 0.6250\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2276 - accuracy: 0.9167 - val_loss: 1.3979 - val_accuracy: 0.6250\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1183 - accuracy: 0.9773 - val_loss: 1.4295 - val_accuracy: 0.5893\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0546 - accuracy: 0.9848 - val_loss: 1.3414 - val_accuracy: 0.6429\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0511 - accuracy: 0.9924 - val_loss: 1.4015 - val_accuracy: 0.6429\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0406 - accuracy: 0.9848 - val_loss: 1.4215 - val_accuracy: 0.6429\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 1.3645 - val_accuracy: 0.6964\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.5400 - val_accuracy: 0.6786\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.6409 - val_accuracy: 0.6786\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.6732 - val_accuracy: 0.6607\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.6752 - val_accuracy: 0.6607\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.6887 - val_accuracy: 0.6429\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.7696 - val_accuracy: 0.6607\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.8134 - val_accuracy: 0.6607\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.8302 - val_accuracy: 0.6786\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8254 - val_accuracy: 0.6786\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8533 - val_accuracy: 0.6786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ea149654c0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_indices, Y_train, epochs = 50, batch_size = 16, shuffle=True, validation_data=(X_test_indices, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8533 - accuracy: 0.6786\n",
      "\n",
      "Test accuracy =  0.6785714030265808\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test_indices, Y_test)\n",
    "print()\n",
    "print(\"Test accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_lbl = test[\"Label\"]\n",
    "Y_test_oh = pd.get_dummies(Y_test_lbl)\n",
    "X_test_indices = sentences_to_indices(test[\"Text\"], word_to_index, maxLen)\n",
    "pred = model.predict(X_test_indices)\n",
    "\n",
    "tabla_predict = []\n",
    "for i in range(len(X_test)):\n",
    "    x = X_test_indices\n",
    "    num = np.argmax(pred[i])\n",
    "    tabla_predict.append([X_test[i],label_to_emoji(Y_test_lbl[i]),label_to_emoji(num).strip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto                                  Label    Predicci√≥n\n",
      "-------------------------------------  -------  ------------\n",
      "I want to eat                          üç¥       üç¥\n",
      "he did not answer                      üòû       üòû\n",
      "he got a raise                         üòÑ       üòÑ\n",
      "she got me a present                   ‚ù§Ô∏è        üòÑ\n",
      "ha ha ha it was so funny               üòÑ       üòÑ\n",
      "he is a good friend                    ‚ù§Ô∏è        üòÑ\n",
      "I am upset                             ‚ù§Ô∏è        üòû\n",
      "We had such a lovely dinner tonight    ‚ù§Ô∏è        üòÑ\n",
      "where is the food                      üç¥       üç¥\n",
      "Stop making this joke ha ha ha         üòÑ       üòÑ\n",
      "where is the ball                      ‚öæ       ‚öæ\n",
      "work is hard                           üòû       üòÑ\n",
      "This girl is messing with me           üòû       ‚ù§Ô∏è\n",
      "are you serious ha ha                  üòÑ       üòû\n",
      "Let us go play baseball                ‚öæ       ‚öæ\n",
      "This stupid grader is not working      üòû       üòû\n",
      "work is horrible                       üòû       üòÑ\n",
      "Congratulation for having a baby       üòÑ       üòÑ\n",
      "stop messing around                    üòû       üòû\n",
      "any suggestions for dinner             üç¥       üç¥\n",
      "I love taking breaks                   ‚ù§Ô∏è        ‚ù§Ô∏è\n",
      "you brighten my day                    üòÑ       üòÑ\n",
      "I boiled rice                          üç¥       üç¥\n",
      "she is a bully                         üòû       ‚ù§Ô∏è\n",
      "Why are you feeling bad                üòû       üòû\n",
      "I am upset                             üòû       üòû\n",
      "I worked during my birthday            üòû       üòÑ\n",
      "My grandmother is the love of my life  ‚ù§Ô∏è        ‚ù§Ô∏è\n",
      "enjoy your break                       üòÑ       ‚öæ\n",
      "valentine day is near                  ‚ù§Ô∏è        üòÑ\n",
      "I miss you so much                     ‚ù§Ô∏è        ‚ù§Ô∏è\n",
      "throw the ball                         ‚öæ       ‚öæ\n",
      "My life is so boring                   üòû       üòû\n",
      "she said yes                           üòÑ       üòÑ\n",
      "will you be my valentine               ‚ù§Ô∏è        üòÑ\n",
      "he can pitch really well               ‚öæ       ‚öæ\n",
      "dance with me                          üòÑ       üòÑ\n",
      "I am starving                          üç¥       üç¥\n",
      "See you at the restaurant              üç¥       üç¥\n",
      "I like to laugh                        üòÑ       üòÑ\n",
      "I will go dance                        üòÑ       ‚öæ\n",
      "I like your jacket                     üòÑ       ‚ù§Ô∏è\n",
      "i miss her                             ‚ù§Ô∏è        ‚ù§Ô∏è\n",
      "what is your favorite baseball game    ‚öæ       ‚öæ\n",
      "Good job                               üòÑ       üòÑ\n",
      "I love to the stars and back           ‚ù§Ô∏è        ‚ù§Ô∏è\n",
      "What you did was awesome               üòÑ       üòÑ\n",
      "ha ha ha lol                           üòÑ       üòÑ\n",
      "I want to joke                         üòÑ       üòû\n",
      "go away                                üòû       ‚öæ\n",
      "yesterday we lost again                üòû       üòû\n",
      "family is all I have                   ‚ù§Ô∏è        ‚ù§Ô∏è\n",
      "you are failing this exercise          üòû       üòû\n",
      "Good joke                              üòÑ       üòÑ\n",
      "You totally deserve this prize         üòÑ       üòÑ\n",
      "I did not have breakfast               üòû       üç¥\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(tabla_predict, headers=[\"Texto\", \"Label\", \"Predicci√≥n\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
